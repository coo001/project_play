import whisper
import sounddevice as sd
import numpy as np
import rtmidi
from difflib import SequenceMatcher

# Whisper ëª¨ë¸ (ì •í™•ë„ ë†’ì´ê¸° ìœ„í•´ small ì‚¬ìš©)
print("ğŸ“¦ Whisper ëª¨ë¸ ë¡œë”© ì¤‘ (small)...")
model = whisper.load_model("small")

# ë§ˆì´í¬ ì„¤ì •
samplerate = 16000
block_duration = 1  # ì´ˆ ë‹¨ìœ„
blocksize = int(samplerate * block_duration)
channels = 1

# íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ ëª©ë¡
CUE_KEYWORDS = {
    "ì—¬ê¸´ ì™œ ì´ë ‡ê²Œ ì–´ë‘ì›Œ": 1,
    "ì§€ê¸ˆ ë¹„ì¶°ì¤˜": 2,
    "ë¬´ëŒ€ ëì´ì•¼": 3
}

# MIDI cue ì‹¤í–‰
def trigger_ma2_cue(cue_number):
    midi_out = rtmidi.MidiOut()
    ports = midi_out.get_ports()
    if not ports:
        print("âŒ MIDI í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # MIDI í¬íŠ¸ ì—´ê¸° (loopMIDI ë“±ìœ¼ë¡œ grandMA2 ì—°ê²°)
    midi_out.open_port(0)

    # MSC ë©”ì‹œì§€ (cue ë²ˆí˜¸ë§Œ ë°”ê¾¸ë©´ ë¨)
    msg = [0xF0, 0x7F, 111, 0x02, 0x01, 0x01, cue_number, 0xF7]
    midi_out.send_message(msg)
    print(f"ğŸ¯ cue {cue_number} ì‹¤í–‰ë¨!")

    midi_out.close_port()

# VAD (Voice Activity Detection): ì—ë„ˆì§€ ê¸°ì¤€ìœ¼ë¡œ ìŒì„± íŒë‹¨
def is_voice_present(audio, threshold=0.01):
    volume = np.sqrt(np.mean(audio**2))
    return volume > threshold

# ìœ ì‚¬ë„ ë¹„êµ
def is_similar(a, b, threshold=0.75):
    return SequenceMatcher(None, a, b).ratio() >= threshold

# ìŒì„± ë¸”ë¡ ì²˜ë¦¬
def process_audio(audio):
    audio = whisper.pad_or_trim(audio.astype(np.float32))
    mel = whisper.log_mel_spectrogram(audio).to(model.device)
    options = whisper.DecodingOptions(language="ko", fp16=False)
    result = whisper.decode(model, mel, options)
    text = result.text.strip()
    if text:
        print(f"ğŸ™ï¸ ì¸ì‹ëœ ëŒ€ì‚¬: {text}")
        for phrase, cue in CUE_KEYWORDS.items():
            if is_similar(phrase, text):
                print(f"ğŸ¯ ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ: \"{phrase}\" â‰ˆ \"{text}\"")
                trigger_ma2_cue(cue)

# ì‹¤ì‹œê°„ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë°
def main():
    print("ğŸ§ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ ì‹œì‘ (Whisper + VAD + ìœ ì‚¬ë„)...")

    def callback(indata, frames, time, status):
        audio_data = indata[:, 0]
        if is_voice_present(audio_data):
            process_audio(audio_data)
        else:
            print("ğŸ¤« (ë¬´ìŒ ë˜ëŠ” ì¡ìŒ)")

    with sd.InputStream(callback=callback, channels=channels, samplerate=samplerate, blocksize=blocksize):
        input("ì—”í„°ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.\n")

if __name__ == "__main__":
    main()
